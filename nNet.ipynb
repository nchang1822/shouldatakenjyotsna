{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as tdata\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(4)\n",
    "torch.manual_seed(7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_price</th>\n",
       "      <th>mid</th>\n",
       "      <th>opened_position_qty</th>\n",
       "      <th>closed_position_qty</th>\n",
       "      <th>transacted_qty</th>\n",
       "      <th>d_open_interest</th>\n",
       "      <th>bid1</th>\n",
       "      <th>bid2</th>\n",
       "      <th>bid3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid2vol</th>\n",
       "      <th>bid3vol</th>\n",
       "      <th>bid4vol</th>\n",
       "      <th>bid5vol</th>\n",
       "      <th>ask1vol</th>\n",
       "      <th>ask2vol</th>\n",
       "      <th>ask3vol</th>\n",
       "      <th>ask4vol</th>\n",
       "      <th>ask5vol</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>3841.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-43</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>3844.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-69</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.6</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>3843.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-35</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  last_price     mid  opened_position_qty   closed_position_qty  \\\n",
       "0   0      3842.4  3842.6                   NaN                  NaN   \n",
       "1   1      3842.8  3843.4                   6.0                 49.0   \n",
       "2   2      3844.0  3844.3                   7.0                 77.0   \n",
       "3   3      3843.8  3843.4                   3.0                 34.0   \n",
       "4   4      3843.2  3843.1                   3.0                 38.0   \n",
       "\n",
       "   transacted_qty  d_open_interest    bid1    bid2    bid3  ...  bid2vol  \\\n",
       "0           103.0                0  3842.4  3842.0  3841.8  ...        1   \n",
       "1            55.0              -43  3843.0  3842.8  3842.4  ...        6   \n",
       "2            84.0              -69  3843.8  3843.6  3843.2  ...        1   \n",
       "3            37.0              -30  3843.0  3842.8  3842.4  ...       13   \n",
       "4            41.0              -35  3842.8  3842.4  3842.0  ...       12   \n",
       "\n",
       "   bid3vol  bid4vol  bid5vol  ask1vol  ask2vol  ask3vol  ask4vol  ask5vol  y  \n",
       "0        6       14        6        6        1        1       10        2  1  \n",
       "1       11        1        6        1        4        4        1       13  0  \n",
       "2        4       21       12        1       16       10        4        9  0  \n",
       "3       12        2        4        2        7        1        2       11  1  \n",
       "4        2        2        4        1        3        1       11       15  1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((592380, 27), (592380,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train and test data as np arrays\n",
    "X0, Y = train_df.values[:, :-1], train_df.values[:, -1]\n",
    "X0.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols where train data is Nan: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# Only columns 3 and 4 (opened_position_qty and closed_position_qty) have NaN's\n",
    "# Have to decide how to handle NaN's at some point\n",
    "print(f'Cols where train data is Nan: {np.where(np.any(np.isnan(X0), axis=0))[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a process function that takes some data and processes it for input to the model\n",
    "Wrapper is a decorator that binds the paramaters from train data to the process function,\n",
    "so process can be a one argument function that takes any data (e.g. test data), and \n",
    "normalizes / processes using saved paramaters from train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(X0):\n",
    "    def get_pars_for_processing(X0):\n",
    "        keep_cols = np.all(~np.isnan(X0), axis=0) # Drop NaN columns\n",
    "        keep_cols[0] = False # Don't keep id\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X0[:, keep_cols])\n",
    "        return scaler, keep_cols\n",
    "    pars = get_pars_for_processing(X0)\n",
    "    def decorator(proc_func):\n",
    "        return lambda X: proc_func(X, pars)\n",
    "    return decorator\n",
    "\n",
    "@wrapper(X0)\n",
    "def process(X, params):\n",
    "    '''\n",
    "    Function that takes training / test data, \n",
    "    and process it for training / evaluation\n",
    "    '''\n",
    "    scaler, keep_cols = params\n",
    "    return scaler.transform(X[:, keep_cols])\n",
    "\n",
    "X = process(X0)\n",
    "(N, D) = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Just gonna take a random 10th for validation\n",
    "val_size = N // 10\n",
    "inds = np.random.permutation(N)\n",
    "X, valX = X[inds[:-val_size]], X[inds[-val_size:]]\n",
    "Y, valY = Y[inds[:-val_size]], Y[inds[-val_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "X, Y = torch.Tensor(X), torch.Tensor(Y)\n",
    "valX, valY = torch.Tensor(valX), torch.Tensor(valY)\n",
    "\n",
    "\n",
    "train_loader = tdata.DataLoader(tdata.TensorDataset(X, Y), \\\n",
    "                                     batch_size=batch_size,\\\n",
    "                                     shuffle=True)\n",
    "val_loader = tdata.DataLoader(tdata.TensorDataset(valX, valY), \\\n",
    "                                     batch_size=batch_size,\\\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on sigmoid\n",
    "Either Option 1:\n",
    "\n",
    "1) No nn.Sigmoid() layer, 2) Use nn.BCEWithLogitsLoss, and 3) apply torch.sigmoid() to output to\n",
    "get probabilities.\n",
    "This option is more numerically stable\n",
    "\n",
    "OR Option 2:\n",
    "\n",
    "1) Use nn.Sigmoid() layer, 2) Use nn.BCELoss(), and 3) Don't need torch.sigmoid() at the prediction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one hidden layer (k units) logistic regression\n",
    "k = 64\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(X.shape[1], k),\n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(k, k//4),\n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(k//4, 1),\n",
    "        #nn.Sigmoid(); #Option 2\n",
    "    )\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.BCELoss(); #Option 2\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1  Loss: 0.6226\n",
      "Train Epoch: 2  Loss: 0.5733\n",
      "Train Epoch: 3  Loss: 0.6239\n",
      "Train Epoch: 4  Loss: 0.6599\n",
      "Train Epoch: 5  Loss: 0.5208\n",
      "Train Epoch: 6  Loss: 0.7705\n",
      "Train Epoch: 7  Loss: 0.7291\n",
      "Train Epoch: 8  Loss: 0.6272\n",
      "Train Epoch: 9  Loss: 0.5971\n",
      "Train Epoch: 10  Loss: 0.6092\n"
     ]
    }
   ],
   "source": [
    "# Some layers, such as Dropout, behave differently during training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Erase accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss (broadcast target to (B, 1), where B is batch size)\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Track loss each epoch\n",
    "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Average loss: 0.0236, Accuracy: 38599/59238 (65.1592)\n"
     ]
    }
   ],
   "source": [
    "# Putting layers like Dropout into evaluation mode\n",
    "model.eval()\n",
    "\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# Turning off automatic differentiation\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        output = torch.sigmoid(model(data))\n",
    "        # output = model(data); #Option 2\n",
    "        \n",
    "        val_loss += criterion(output, target.unsqueeze(1)).item()  # Sum up batch loss\n",
    "        pred = output.round()\n",
    "        correct += (pred.eq(target.view_as(pred))).sum().item()\n",
    "\n",
    "val_loss /= len(val_loader.dataset)\n",
    "\n",
    "print('Val set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
    "      (val_loss, correct, len(val_loader.dataset),\n",
    "       100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "tX = process(test_df.values)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = torch.sigmoid(model(torch.Tensor(tX)))\n",
    "    #output = model(torch.Tensor(tX)); #Option 2\n",
    "    \n",
    "output_df = pd.DataFrame({'id':test_df['id'], 'Predicted':output.data.numpy().squeeze()})\n",
    "output_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data to make sure logistic regression worked lmao\n",
    "import sys\n",
    "sys.path.append('~/git/MLModels')\n",
    "from MLModels import utils as u\n",
    "from MLModels import linearModels as lm\n",
    "\n",
    "f, line = u.genF(zero_one=True)\n",
    "X, Y = u.genData(f, 10000)\n",
    "(N, D) = X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
